import { pgTable, check, integer, varchar, index, unique, serial, date, timestamp, doublePrecision, text, geometry, foreignKey, jsonb, uuid, pgView } from "drizzle-orm/pg-core"
import { sql } from "drizzle-orm"



export const spatialRefSys = pgTable("spatial_ref_sys", {
	srid: integer().primaryKey().notNull(),
	authName: varchar("auth_name", { length: 256 }),
	authSrid: integer("auth_srid"),
	srtext: varchar({ length: 2048 }),
	proj4Text: varchar({ length: 2048 }),
}, (table) => [
	check("spatial_ref_sys_srid_check", sql`(srid > 0) AND (srid <= 998999)`),
]);

export const trafficSignalVolumes = pgTable("traffic_signal_volumes", {
	id: serial().primaryKey().notNull(),
	scatsSite: integer("scats_site").notNull(),
	intervalDate: date("interval_date").notNull(),
	detectorNumber: integer("detector_number").notNull(),
	v00: integer(),
	v01: integer(),
	v02: integer(),
	v03: integer(),
	v04: integer(),
	v05: integer(),
	v06: integer(),
	v07: integer(),
	v08: integer(),
	v09: integer(),
	v10: integer(),
	v11: integer(),
	v12: integer(),
	v13: integer(),
	v14: integer(),
	v15: integer(),
	v16: integer(),
	v17: integer(),
	v18: integer(),
	v19: integer(),
	v20: integer(),
	v21: integer(),
	v22: integer(),
	v23: integer(),
	v24: integer(),
	v25: integer(),
	v26: integer(),
	v27: integer(),
	v28: integer(),
	v29: integer(),
	v30: integer(),
	v31: integer(),
	v32: integer(),
	v33: integer(),
	v34: integer(),
	v35: integer(),
	v36: integer(),
	v37: integer(),
	v38: integer(),
	v39: integer(),
	v40: integer(),
	v41: integer(),
	v42: integer(),
	v43: integer(),
	v44: integer(),
	v45: integer(),
	v46: integer(),
	v47: integer(),
	v48: integer(),
	v49: integer(),
	v50: integer(),
	v51: integer(),
	v52: integer(),
	v53: integer(),
	v54: integer(),
	v55: integer(),
	v56: integer(),
	v57: integer(),
	v58: integer(),
	v59: integer(),
	v60: integer(),
	v61: integer(),
	v62: integer(),
	v63: integer(),
	v64: integer(),
	v65: integer(),
	v66: integer(),
	v67: integer(),
	v68: integer(),
	v69: integer(),
	v70: integer(),
	v71: integer(),
	v72: integer(),
	v73: integer(),
	v74: integer(),
	v75: integer(),
	v76: integer(),
	v77: integer(),
	v78: integer(),
	v79: integer(),
	v80: integer(),
	v81: integer(),
	v82: integer(),
	v83: integer(),
	v84: integer(),
	v85: integer(),
	v86: integer(),
	v87: integer(),
	v88: integer(),
	v89: integer(),
	v90: integer(),
	v91: integer(),
	v92: integer(),
	v93: integer(),
	v94: integer(),
	v95: integer(),
	region: varchar({ length: 50 }),
	recordCount: integer("record_count"),
	volume24Hour: integer("volume_24hour"),
	alarm24Hour: integer("alarm_24hour"),
	createdAt: timestamp("created_at", { mode: 'string' }).default(sql`CURRENT_TIMESTAMP`),
	updatedAt: timestamp("updated_at", { mode: 'string' }).default(sql`CURRENT_TIMESTAMP`),
}, (table) => [
	index("idx_interval_date").using("btree", table.intervalDate.asc().nullsLast().op("date_ops")),
	index("idx_region").using("btree", table.region.asc().nullsLast().op("text_ops")),
	index("idx_scats_site").using("btree", table.scatsSite.asc().nullsLast().op("int4_ops")),
	index("idx_scats_site_date").using("btree", table.scatsSite.asc().nullsLast().op("int4_ops"), table.intervalDate.asc().nullsLast().op("int4_ops")),
	unique("unique_traffic_reading").on(table.scatsSite, table.intervalDate, table.detectorNumber),
]);

export const seweragePipelines = pgTable("sewerage_pipelines", {
	id: serial().primaryKey().notNull(),
	objectid: integer().notNull(),
	mxunitid: varchar({ length: 100 }).notNull(),
	mxsiteid: varchar({ length: 50 }),
	compkey: integer(),
	comptype: integer(),
	unitid: varchar({ length: 50 }),
	unitid2: varchar({ length: 50 }),
	parallelLineNbr: varchar("parallel_line_nbr", { length: 10 }),
	unittype: varchar({ length: 20 }),
	unittypeDesc: varchar("unittype_desc", { length: 100 }),
	sewerName: varchar("sewer_name", { length: 200 }),
	assetId: varchar("asset_id", { length: 50 }),
	alternateAssetId: varchar("alternate_asset_id", { length: 50 }),
	subarea: varchar({ length: 50 }),
	material: varchar({ length: 50 }),
	upstreamIl: doublePrecision("upstream_il"),
	downstreamIl: doublePrecision("downstream_il"),
	pipeLength: doublePrecision("pipe_length"),
	pipeWidth: integer("pipe_width"),
	pipeHeight: integer("pipe_height"),
	grade: doublePrecision(),
	dateRelined: timestamp("date_relined", { mode: 'string' }),
	dateOfConstruction: timestamp("date_of_construction", { mode: 'string' }),
	epmsSecNo: varchar("epms_sec_no", { length: 50 }),
	asconstPlanNo: varchar("asconst_plan_no", { length: 50 }),
	source: varchar({ length: 100 }),
	methodOfCapture: varchar("method_of_capture", { length: 100 }),
	dateCaptured: timestamp("date_captured", { mode: 'string' }),
	dateLastUpdated: timestamp("date_last_updated", { mode: 'string' }),
	serviceStatus: varchar("service_status", { length: 20 }),
	serviceStatusChgDate: timestamp("service_status_chg_date", { mode: 'string' }),
	serviceStatusPlanNo: varchar("service_status_plan_no", { length: 50 }),
	comments: text(),
	miPrinx: integer("mi_prinx"),
	geom: geometry({ type: "geometry", srid: 4326 }),
	createdAt: timestamp("created_at", { mode: 'string' }).default(sql`CURRENT_TIMESTAMP`),
	updatedAt: timestamp("updated_at", { mode: 'string' }).default(sql`CURRENT_TIMESTAMP`),
}, (table) => [
	index("idx_sewerage_pipelines_geom").using("gist", table.geom.asc().nullsLast().op("gist_geometry_ops_2d")),
	index("idx_sewerage_pipelines_mxunitid").using("btree", table.mxunitid.asc().nullsLast().op("text_ops")),
	index("idx_sewerage_pipelines_service_status").using("btree", table.serviceStatus.asc().nullsLast().op("text_ops")),
	index("idx_sewerage_pipelines_sewer_name").using("btree", table.sewerName.asc().nullsLast().op("text_ops")),
	index("idx_sewerage_pipelines_unittype").using("btree", table.unittype.asc().nullsLast().op("text_ops")),
	unique("unique_sewerage_pipeline").on(table.objectid),
]);

export const pdf = pgTable("pdf", {
	id: serial().primaryKey().notNull(),
	name: text().notNull(),
	createdAt: timestamp("created_at", { mode: 'string' }).defaultNow().notNull(),
	updatedAt: timestamp("updated_at", { mode: 'string' }).defaultNow().notNull(),
}, (table) => [
	unique("pdf_name_unique").on(table.name),
]);

export const domBindings = pgTable("dom_bindings", {
	id: serial().primaryKey().notNull(),
	pdfId: integer("pdf_id").notNull(),
	path: text().notNull(),
	stateBinding: text("state_binding").notNull(),
	properties: jsonb().default({}).notNull(),
	createdAt: timestamp("created_at", { mode: 'string' }).defaultNow().notNull(),
	updatedAt: timestamp("updated_at", { mode: 'string' }).defaultNow().notNull(),
}, (table) => [
	index("idx_dom_bindings_pdf_id").using("btree", table.pdfId.asc().nullsLast().op("int4_ops")),
	index("idx_dom_bindings_state").using("btree", table.stateBinding.asc().nullsLast().op("text_ops")),
	foreignKey({
			columns: [table.pdfId],
			foreignColumns: [pdf.id],
			name: "dom_bindings_pdf_id_pdf_id_fk"
		}).onDelete("cascade"),
]);

export const rentalAppraisalData = pgTable("rental_appraisal_data", {
	data: jsonb().notNull(),
	createdAt: timestamp("created_at", { mode: 'string' }).defaultNow().notNull(),
	updatedAt: timestamp("updated_at", { mode: 'string' }).defaultNow().notNull(),
	id: uuid().primaryKey().notNull(),
	status: varchar({ length: 50 }).default('pending').notNull(),
	pdfUrl: text("pdf_url"),
}, (table) => [
	unique("rental_appraisal_data_identifier_key").on(table.id),
]);
export const geographyColumns = pgView("geography_columns", {	// TODO: failed to parse database type 'name'
	fTableCatalog: unknown("f_table_catalog"),
	// TODO: failed to parse database type 'name'
	fTableSchema: unknown("f_table_schema"),
	// TODO: failed to parse database type 'name'
	fTableName: unknown("f_table_name"),
	// TODO: failed to parse database type 'name'
	fGeographyColumn: unknown("f_geography_column"),
	coordDimension: integer("coord_dimension"),
	srid: integer(),
	type: text(),
}).as(sql`SELECT current_database() AS f_table_catalog, n.nspname AS f_table_schema, c.relname AS f_table_name, a.attname AS f_geography_column, postgis_typmod_dims(a.atttypmod) AS coord_dimension, postgis_typmod_srid(a.atttypmod) AS srid, postgis_typmod_type(a.atttypmod) AS type FROM pg_class c, pg_attribute a, pg_type t, pg_namespace n WHERE t.typname = 'geography'::name AND a.attisdropped = false AND a.atttypid = t.oid AND a.attrelid = c.oid AND c.relnamespace = n.oid AND (c.relkind = ANY (ARRAY['r'::"char", 'v'::"char", 'm'::"char", 'f'::"char", 'p'::"char"])) AND NOT pg_is_other_temp_schema(c.relnamespace) AND has_table_privilege(c.oid, 'SELECT'::text)`);

export const geometryColumns = pgView("geometry_columns", {	fTableCatalog: varchar("f_table_catalog", { length: 256 }),
	// TODO: failed to parse database type 'name'
	fTableSchema: unknown("f_table_schema"),
	// TODO: failed to parse database type 'name'
	fTableName: unknown("f_table_name"),
	// TODO: failed to parse database type 'name'
	fGeometryColumn: unknown("f_geometry_column"),
	coordDimension: integer("coord_dimension"),
	srid: integer(),
	type: varchar({ length: 30 }),
}).as(sql`WITH constraint_defs AS ( SELECT pg_constraint.connamespace, pg_constraint.conrelid, pg_constraint.conkey, regexp_replace(pg_get_constraintdef(pg_constraint.oid), '\s+NOT\s+VALID'::text, ''::text, 'i'::text) AS consrc FROM pg_constraint ) SELECT current_database()::character varying(256) AS f_table_catalog, n.nspname AS f_table_schema, c.relname AS f_table_name, a.attname AS f_geometry_column, COALESCE(postgis_typmod_dims(a.atttypmod), sn.ndims, 2) AS coord_dimension, COALESCE(NULLIF(postgis_typmod_srid(a.atttypmod), 0), sr.srid, 0) AS srid, replace(replace(COALESCE(NULLIF(upper(postgis_typmod_type(a.atttypmod)), 'GEOMETRY'::text), st.type, 'GEOMETRY'::text), 'ZM'::text, ''::text), 'Z'::text, ''::text)::character varying(30) AS type FROM pg_class c JOIN pg_attribute a ON a.attrelid = c.oid AND NOT a.attisdropped JOIN pg_namespace n ON c.relnamespace = n.oid JOIN pg_type t ON a.atttypid = t.oid LEFT JOIN ( SELECT s.connamespace, s.conrelid, s.conkey, (regexp_match(s.consrc, 'geometrytype\(\w+\)\s*=\s*''(\w+)'''::text, 'i'::text))[1] AS type FROM constraint_defs s WHERE s.consrc ~* 'geometrytype\(\w+\)\s*=\s*''\w+'''::text) st ON st.connamespace = n.oid AND st.conrelid = c.oid AND (a.attnum = ANY (st.conkey)) LEFT JOIN ( SELECT s.connamespace, s.conrelid, s.conkey, (regexp_match(s.consrc, 'ndims\(\w+\)\s*=\s*(\d+)'::text, 'i'::text))[1]::integer AS ndims FROM constraint_defs s WHERE s.consrc ~* 'ndims\(\w+\)\s*=\s*\d+'::text) sn ON sn.connamespace = n.oid AND sn.conrelid = c.oid AND (a.attnum = ANY (sn.conkey)) LEFT JOIN ( SELECT s.connamespace, s.conrelid, s.conkey, (regexp_match(s.consrc, 'srid\(\w+\)\s*=\s*(\d+)'::text, 'i'::text))[1]::integer AS srid FROM constraint_defs s WHERE s.consrc ~* 'srid\(\w+\)\s*=\s*\d+'::text) sr ON sr.connamespace = n.oid AND sr.conrelid = c.oid AND (a.attnum = ANY (sr.conkey)) WHERE (c.relkind = ANY (ARRAY['r'::"char", 'v'::"char", 'm'::"char", 'f'::"char", 'p'::"char"])) AND NOT c.relname = 'raster_columns'::name AND t.typname = 'geometry'::name AND NOT pg_is_other_temp_schema(c.relnamespace) AND has_table_privilege(c.oid, 'SELECT'::text)`);

export const peakHourVolumes = pgView("peak_hour_volumes", {	scatsSite: integer("scats_site"),
	intervalDate: date("interval_date"),
	detectorNumber: integer("detector_number"),
	region: varchar({ length: 50 }),
	morningPeakVolume: integer("morning_peak_volume"),
	eveningPeakVolume: integer("evening_peak_volume"),
	volume24Hour: integer("volume_24hour"),
}).as(sql`SELECT scats_site, interval_date, detector_number, region, v28 + v29 + v30 + v31 + v32 + v33 + v34 + v35 AS morning_peak_volume, v68 + v69 + v70 + v71 + v72 + v73 + v74 + v75 AS evening_peak_volume, volume_24hour FROM traffic_signal_volumes`);